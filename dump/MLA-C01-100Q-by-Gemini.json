[
    {
        "question": "데이터 전처리, 모델 학습, 모델 등록을 포함하는 워크플로를 자동화해야 합니다. 이 워크플로는 버전 관리가 가능해야 하며 단계별 문제 해결(Troubleshooting)이 가능해야 합니다. 다음 중 이 요구 사항에 가장 적합한 AWS 서비스 또는 기능은 무엇입니까?",
        "options": [
            "A. AWS Lambda와 Step Functions",
            "B. Amazon SageMaker Pipelines",
            "C. Amazon SageMaker Processing jobs",
            "D. AWS Glue Workflows"
        ],
        "answer": "B",
        "explanation": "SageMaker Pipelines는 ML을 위해 구축된 전용 CI/CD 서비스로, 엔드투엔드 ML 워크플로를 생성, 자동화 및 관리할 수 있게 해줍니다. 기본적으로 버전 관리를 지원하며 시각적 인터페이스를 통해 각 단계의 문제를 해결할 수 있습니다."
    },
    {
        "question": "한 회사가 실시간 추론(Real-time inference)을 위해 Amazon SageMaker를 사용하고 있습니다. 최근 입력 데이터의 통계적 특성 변화로 인해 시간이 지남에 따라 모델 성능이 저하되는 것을 발견했습니다. ML 엔지니어가 이 문제를 자동으로 감지하기 위해 구현해야 하는 기능은 무엇입니까?",
        "options": [
            "A. SageMaker Clarify",
            "B. SageMaker Debugger",
            "C. SageMaker Model Monitor",
            "D. SageMaker Feature Store"
        ],
        "answer": "C",
        "explanation": "SageMaker Model Monitor는 배포된 모델의 데이터 품질, 모델 품질, 편향(bias)을 모니터링하여 운영 환경에서의 컨셉 드리프트(Concept drift) 및 데이터 드리프트를 자동으로 감지합니다."
    },
    {
        "question": "ML 엔지니어가 Amazon S3에 저장된 대규모 데이터 세트를 위한 특성 공학(Feature engineering) 파이프라인을 구축하고 있습니다. 이 프로세스에는 복잡한 조인과 변환이 필요하며, 여러 ML 프로젝트에서 재사용되어야 합니다. 이러한 특성(Feature)들을 관리하는 가장 효율적인 방법은 무엇입니까?",
        "options": [
            "A. 변환된 데이터를 Parquet 형식으로 S3에 다시 저장한다.",
            "B. Amazon SageMaker Feature Store를 사용하여 특성을 수집하고 관리한다.",
            "C. 특성을 저장하고 조회하기 위해 DynamoDB 테이블을 생성한다.",
            "D. AWS Glue DataBrew를 사용하여 변환 레시피를 저장한다."
        ],
        "answer": "B",
        "explanation": "SageMaker Feature Store는 ML 특성을 저장, 업데이트, 검색 및 공유하기 위한 전용 리포지토리입니다. 온라인 및 오프라인 저장소를 모두 지원하여 프로젝트 간의 재사용성과 일관성을 유지하는 데 이상적입니다."
    },
    {
        "question": "데이터 과학자가 가끔씩만 트래픽이 발생하는 가벼운 ML 모델을 배포하려고 합니다. 회사는 비용을 최소화하고 유휴 컴퓨팅 인스턴스에 대한 비용 지불을 피하고 싶어 합니다. ML 엔지니어는 어떤 SageMaker 추론 옵션을 선택해야 합니까?",
        "options": [
            "A. SageMaker Real-time inference",
            "B. SageMaker Batch transform",
            "C. SageMaker Serverless inference",
            "D. SageMaker Asynchronous inference"
        ],
        "answer": "C",
        "explanation": "SageMaker Serverless Inference는 간헐적이거나 불규칙한 트래픽이 있는 워크로드에 적합합니다. 추론 요청을 처리하는 데 사용된 컴퓨팅 시간에 대해서만 비용을 지불하므로 유휴 리소스 비용이 발생하지 않습니다."
    },
    {
        "question": "ML 엔지니어가 SageMaker 학습 작업(Training job)을 위한 데이터 암호화 전략을 구현해야 합니다. 보안 정책에 따라 암호화 키는 회사의 보안 팀에서 직접 관리하고 교체(Rotation)해야 합니다. 어떤 접근 방식을 취해야 합니까?",
        "options": [
            "A. S3 관리형 암호화 키(SSE-S3)를 사용한다.",
            "B. 고객 관리형 키(CMK)를 사용하는 AWS KMS를 사용한다.",
            "C. AWS 관리형 키(SSE-KMS)를 사용하는 AWS KMS를 사용한다.",
            "D. S3에 업로드하기 전에 로컬에서 데이터를 암호화한다."
        ],
        "answer": "B",
        "explanation": "AWS KMS의 고객 관리형 키(CMK)를 사용하면 사용자가 키의 수명 주기, 교체 및 액세스 정책을 완전히 제어할 수 있으므로 보안 팀의 요구 사항을 충족할 수 있습니다."
    },
    {
        "question": "한 회사가 대규모 이미지 데이터 세트를 사용하여 Amazon SageMaker에서 컴퓨터 비전 모델을 학습시키고 있습니다. 학습 데이터는 Amazon S3에 저장되어 있으며, 데이터의 크기가 너무 커서 각 학습 인스턴스의 디스크 용량을 초과합니다. 데이터 전체를 다운로드하지 않고 학습 성능을 최적화하기 위해 ML 엔지니어가 선택해야 하는 S3 데이터 입력 모드는 무엇입니까?",
        "options": [
            "A. File mode",
            "B. Pipe mode",
            "C. Fast File mode",
            "D. Distributed mode"
        ],
        "answer": "C",
        "explanation": "Fast File mode는 S3 객체를 로컬 파일 시스템에 마운트하여 POSIX 인터페이스로 접근하게 해줍니다. 전체 데이터를 다운로드할 필요 없이 필요한 시점에 스트리밍하므로 디스크 용량 문제를 해결하고 File mode보다 시작 시간이 빠릅니다."
    },
    {
        "question": "금융 서비스 기업이 대출 승인 모델의 예측 결과에 대해 '왜 특정 사용자의 대출이 거부되었는지'에 대한 설명을 제공해야 합니다. 규제 준수를 위해 모델의 특성 중요도(Feature Importance)와 개별 예측에 대한 기여도를 분석하는 데 가장 적합한 도구는 무엇입니까?",
        "options": [
            "A. SageMaker Model Monitor",
            "B. SageMaker Clarify",
            "C. SageMaker Debugger",
            "D. SageMaker Lineage Config"
        ],
        "answer": "B",
        "explanation": "SageMaker Clarify는 SHAP(Shapley Additive Explanations) 값을 사용하여 모델의 예측에 대한 설명 가능성(Explainability)을 제공하며, 훈련 데이터 및 모델의 편향을 탐지합니다."
    },
    {
        "question": "운영 팀에서 SageMaker 학습 작업 중 발생하는 CPU 및 GPU 리소스 사용률을 실시간으로 모니터링하고, 특정 임계값을 초과할 경우 알림을 받고 싶어 합니다. 어떤 서비스 조합을 사용해야 합니까?",
        "options": [
            "A. SageMaker Profiler와 AWS CloudTrail",
            "B. Amazon CloudWatch와 Amazon SNS",
            "C. AWS Config와 Amazon EventBridge",
            "D. SageMaker Debugger와 AWS Lambda"
        ],
        "answer": "B",
        "explanation": "SageMaker는 지표를 Amazon CloudWatch로 전송합니다. CloudWatch Alarms를 설정하여 임계값 도달 시 Amazon SNS를 통해 알림을 보낼 수 있습니다."
    },
    {
        "question": "ML 엔지니어가 수천 개의 작은 CSV 파일로 구성된 데이터 세트를 사용하여 모델을 학습시키고 있습니다. 학습 시작 시 S3에서 파일을 가져오는 데 시간이 너무 오래 걸려 GPU 유휴 시간이 발생하고 있습니다. 이를 해결하기 위한 가장 효율적인 방법은 무엇입니까?",
        "options": [
            "A. 인스턴스 유형을 더 높은 네트워크 대역폭을 가진 유형으로 변경한다.",
            "B. 데이터를 Apache Parquet 또는 TFRecord 형식으로 변환하여 파일 수를 줄인다.",
            "C. S3 Transfer Acceleration을 활성화한다.",
            "D. 모든 데이터를 하나의 대형 텍스트 파일로 합친다."
        ],
        "answer": "B",
        "explanation": "작은 파일이 너무 많으면 S3의 List 및 Get 요청 오버헤드로 인해 데이터 수집 성능이 저하됩니다. 데이터를 RecordIO, TFRecord 또는 Parquet와 같은 최적화된 형식으로 병합하면 I/O 성능이 크게 향상됩니다."
    },
    {
        "question": "모델의 하이퍼파라미터 튜닝(HPO)을 수행할 때, 비용을 최소화하면서도 최적의 조합을 찾기 위해 SageMaker에서 권장되는 전략은 무엇입니까?",
        "options": [
            "A. Random Search를 사용하고 최대 실행 시간을 늘린다.",
            "B. Bayesian Search를 사용하고 전략적 중단(Early Stopping)을 활성화한다.",
            "C. Grid Search를 사용하여 모든 조합을 테스트한다.",
            "D. 모든 학습 작업을 Spot Instances에서만 실행한다."
        ],
        "answer": "B",
        "explanation": "Bayesian Search는 이전 결과를 바탕으로 유망한 조합을 지능적으로 탐색하며, Early Stopping은 성능 개선 가능성이 낮은 작업을 조기에 종료시켜 비용을 절감합니다."
    },
    {
        "question": "SageMaker 추론 엔드포인트의 가용성을 높이기 위해 다중 가용 영역(Multi-AZ)에 배포하려고 합니다. 엔지니어가 설정해야 할 사항은 무엇입니까?",
        "options": [
            "A. 엔드포인트 설정(Endpoint Config)에서 InstanceCount를 2 이상으로 설정한다.",
            "B. 각 AZ에 대해 별도의 엔드포인트를 생성한다.",
            "C. AWS Global Accelerator를 엔드포인트 앞에 배치한다.",
            "D. SageMaker는 기본적으로 단일 AZ만 지원하므로 직접 EC2에 배포해야 한다."
        ],
        "answer": "A",
        "explanation": "SageMaker 관리형 엔드포인트에서 InstanceCount를 2 이상으로 설정하면 AWS는 가용성을 위해 자동으로 인스턴스를 여러 가용 영역(AZ)에 분산 배치합니다."
    },
    {
        "question": "기존에 학습된 오픈 소스 모델(예: Hugging Face 모델)을 SageMaker로 가져와서 추론을 수행하려고 합니다. 모델 아티팩트와 추론 코드를 포함하기 위해 가장 유연한 방법은 무엇입니까?",
        "options": [
            "A. SageMaker 내장 알고리즘만 사용한다.",
            "B. 사용자 지정 Docker 이미지를 생성하여 Amazon ECR에 푸시한 후 사용한다.",
            "C. S3에 모델 파일만 업로드하고 AWS Lambda에서 호출한다.",
            "D. SageMaker Canvas를 사용하여 모델을 다시 빌드한다."
        ],
        "answer": "B",
        "explanation": "Bring-Your-Own-Container(BYOC) 모델을 사용하면 Docker 이미지를 통해 라이브러리, 종속성 및 추론 로직을 완전히 제어할 수 있어 가장 유연합니다."
    },
    {
        "question": "온프레미스 데이터베이스에서 S3로 매일 증분 데이터를 추출하여 ML 학습에 사용하려고 합니다. 코드를 최소화하면서 데이터 변환 및 로드(ETL)를 수행하기에 가장 적합한 서비스는 무엇입니까?",
        "options": [
            "A. Amazon EMR",
            "B. AWS Glue",
            "C. AWS Batch",
            "D. Amazon EC2 자가 관리형 스크립트"
        ],
        "answer": "B",
        "explanation": "AWS Glue는 서버리스 ETL 서비스로, 데이터 카탈로그 생성 및 자동화된 데이터 변환 파이프라인 구축에 최적화되어 있습니다."
    },
    {
        "question": "새로운 모델 버전을 배포할 때, 전체 트래픽의 10%만 새 버전으로 먼저 보내고 점진적으로 늘려가며 성능을 검증하는 배포 전략은 무엇입니까?",
        "options": [
            "A. Blue/Green 배포",
            "B. Canary 배포",
            "C. All-at-once 배포",
            "D. Rolling 배포"
        ],
        "answer": "B",
        "explanation": "Canary 배포는 소량의 트래픽을 새 버전에 먼저 노출하여 안정성을 확인한 후 단계적으로 확대하는 방식입니다."
    },
    {
        "question": "SageMaker Studio 내에서 팀 구성원 간에 노트북과 코드를 안전하게 공유하고 협업하기 위해 가장 권장되는 연동 도구는 무엇입니까?",
        "options": [
            "A. Amazon S3 버킷 공유",
            "B. AWS CodeCommit 또는 GitHub와 같은 Git 리포지토리",
            "C. 이메일로 .ipynb 파일 전송",
            "D. AWS CloudShell 공유"
        ],
        "answer": "B",
        "explanation": "SageMaker Studio는 Git 연동을 지원하므로 리포지토리를 통해 버전 관리 및 팀 간 협업을 안전하고 효율적으로 수행할 수 있습니다."
    },
    {
        "question": "한 회사가 대규모 데이터 세트를 Amazon S3에서 Amazon SageMaker로 스트리밍하여 학습 시간을 단축하고자 합니다. 데이터는 현재 수백만 개의 작은 파일로 저장되어 있어 I/O 성능 저하가 우려됩니다. ML 엔지니어가 데이터 처리 효율을 높이기 위해 데이터를 변환해야 할 가장 권장되는 형식은 무엇입니까?",
        "options": [
            "A. JSON Lines (.jsonl)",
            "B. Apache Parquet",
            "C. RecordIO-protobuf",
            "D. 원본 CSV 유지"
        ],
        "answer": "C",
        "explanation": "SageMaker의 내장 알고리즘은 RecordIO-protobuf 형식을 사용할 때 최적의 성능을 발휘합니다. 특히 Pipe 모드와 결합하면 데이터를 스트리밍 방식으로 읽어들여 학습 속도를 극대화할 수 있습니다."
    },
    {
        "question": "보안 규정에 따라 SageMaker 학습 작업이 인터넷을 통하지 않고 사설 네트워크 내에서만 Amazon S3에 접근해야 합니다. 이를 위해 구성해야 하는 VPC 구성 요소는 무엇입니까?",
        "options": [
            "A. NAT Gateway",
            "B. Internet Gateway",
            "C. S3 VPC Gateway Endpoint",
            "D. Transit Gateway"
        ],
        "answer": "C",
        "explanation": "S3 VPC Gateway Endpoint를 사용하면 트래픽이 AWS 네트워크를 벗어나지 않고 VPC 내부에서 S3에 직접 접근할 수 있어 보안성이 높아지고 데이터 전송 비용을 절감할 수 있습니다."
    },
    {
        "question": "모델 학습 중 가중치(Weights)와 편향(Bias) 같은 내부 텐서 데이터를 수집하여 학습 과정의 이상 징후(예: Vanishing Gradient)를 시각화하고 감지하고 싶습니다. 어떤 기능을 사용해야 합니까?",
        "options": [
            "A. SageMaker Model Monitor",
            "B. SageMaker Debugger",
            "C. SageMaker Clarify",
            "D. Amazon CloudWatch Logs"
        ],
        "answer": "B",
        "explanation": "SageMaker Debugger는 학습 과정 중 모델의 내부 상태를 캡처하여 디버깅 지표를 제공하며, 특정 규칙(Rule)을 설정해 이상 징후 발생 시 학습을 자동 중단할 수도 있습니다."
    },
    {
        "question": "기업 내 여러 팀이 동일한 데이터 세트에서 추출한 특성(Feature)들을 공유하여 중복 작업을 줄이고 싶어 합니다. 또한, 실시간 추론 시 짧은 지연 시간(Low Latency)으로 특성값을 읽어와야 합니다. 가장 적합한 서비스는?",
        "options": [
            "A. Amazon RDS",
            "B. Amazon SageMaker Feature Store",
            "C. Amazon ElastiCache",
            "D. Amazon Redshift"
        ],
        "answer": "B",
        "explanation": "SageMaker Feature Store는 온라인 저장소(실시간 추론용)와 오프라인 저장소(학습용)를 모두 지원하며, 조직 내에서 특성을 공유하고 재사용할 수 있는 중앙 집중식 저장소 역할을 합니다."
    },
    {
        "question": "SageMaker 엔드포인트에 배포된 모델이 특정 가용 영역(AZ) 장애 시에도 서비스가 중단되지 않도록 보장하려고 합니다. 가장 효과적인 조치는 무엇입니까?",
        "options": [
            "A. 엔드포인트 구성에서 'ProductionVariants'의 'InitialInstanceCount'를 2 이상으로 설정한다.",
            "B. 동일한 모델을 다른 리전에 배포하고 Route 53으로 연결한다.",
            "C. 엔드포인트를 매시간 백업한다.",
            "D. Elastic Load Balancer를 엔드포인트 앞에 수동으로 배치한다."
        ],
        "answer": "A",
        "explanation": "SageMaker는 인스턴스 개수를 2개 이상으로 설정하면 자동으로 여러 가용 영역에 분산 배치하여 고가용성을 보장하는 관리형 서비스를 제공합니다."
    },
    {
        "question": "학습 데이터 세트가 불균형(Imbalanced)하여 모델이 특정 클래스에 편향될 위험이 있습니다. 훈련 전 데이터 세트의 편향 정도를 측정하는 데 가장 적합한 SageMaker 기능은?",
        "options": [
            "A. SageMaker Model Monitor",
            "B. SageMaker Clarify",
            "C. SageMaker Ground Truth",
            "D. SageMaker Autopilot"
        ],
        "answer": "B",
        "explanation": "SageMaker Clarify는 훈련 전(Pre-training) 데이터 세트의 편향 지표를 계산하고, 훈련 후(Post-training) 모델 예측의 편향성을 분석하는 기능을 제공합니다."
    },
    {
        "question": "비용 절감을 위해 SageMaker 학습 작업에 'Managed Spot Training'을 도입하려고 합니다. 학습이 중단되었을 때 처음부터 다시 시작하지 않도록 하려면 무엇을 구현해야 합니까?",
        "options": [
            "A. S3 Transfer Acceleration 활성화",
            "B. 체크포인트(Checkpointing) 로직 구현 및 S3 경로 지정",
            "C. 인스턴스 유형을 성능이 낮은 것으로 변경",
            "D. 학습 속도를 높이기 위해 배치 크기 축소"
        ],
        "answer": "B",
        "explanation": "Managed Spot Training은 비용을 최대 90% 절감해주지만 인스턴스가 회수될 수 있습니다. 이때 S3에 체크포인트를 저장하도록 설정하면 중단된 지점부터 학습을 재개할 수 있습니다."
    },
    {
        "question": "분산 학습(Distributed Training)을 수행할 때, 여러 노드 간의 파라미터 업데이트를 효율적으로 관리하여 대규모 모델 학습 속도를 높여주는 SageMaker 전용 라이브러리는 무엇입니까?",
        "options": [
            "A. SageMaker Data Wrangler",
            "B. SageMaker Distributed Data Parallel (SMDDP)",
            "C. SageMaker Edge Manager",
            "D. Amazon Elastic Inference"
        ],
        "answer": "B",
        "explanation": "SMDDP 라이브러리는 AWS 인프라에 최적화된 통신 알고리즘을 사용하여 Horovod나 PyTorch 분산 학습보다 더 높은 성능을 제공합니다."
    },
    {
        "question": "사용자가 직접 레이블링하지 않은 방대한 양의 원시 데이터를 가지고 있습니다. Amazon SageMaker를 사용하여 데이터 레이블링 프로세스를 자동화하고 효율화하는 서비스는?",
        "options": [
            "A. SageMaker Canvas",
            "B. SageMaker Ground Truth",
            "C. SageMaker Studio Lab",
            "D. SageMaker JumpStart"
        ],
        "answer": "B",
        "explanation": "SageMaker Ground Truth는 인간 레이블러와 머신러닝 기반 자동 레이블링(Active Learning)을 결합하여 데이터 세트 구축 비용과 시간을 크게 줄여줍니다."
    },
    {
        "question": "ML 엔지니어가 모델의 하이퍼파라미터 튜닝을 수행할 때, 검색 공간이 너무 넓어 비용이 우려됩니다. 성능이 낮은 시도를 조기에 중단하여 자원을 절약하는 설정은?",
        "options": [
            "A. Random Search 전략 사용",
            "B. Early Stopping 활성화",
            "C. 최대 병렬 실행 수(MaxParallelTrainingJobs) 증가",
            "D. Warm Start 사용"
        ],
        "answer": "B",
        "explanation": "Early Stopping 정책을 사용하면 성능 개선 가능성이 낮은 학습 작업을 SageMaker가 자동으로 감지하여 조기에 종료하므로 컴퓨팅 비용을 아낄 수 있습니다."
    },
    {
        "question": "한 회사에서 수백 개의 모델 엔드포인트를 운영하고 있으며, 각 엔드포인트는 가끔씩만 사용됩니다. 관리 오버헤드와 인스턴스 유지 비용을 줄이기 위해 여러 모델을 단일 엔드포인트에 배포하여 리소스를 공유하고자 합니다. 어떤 기능을 사용해야 합니까?",
        "options": [
            "A. Multi-model endpoints (MME)",
            "B. Multi-container endpoints (MCE)",
            "C. SageMaker Serverless Inference",
            "D. Inference Pipelines"
        ],
        "answer": "A",
        "explanation": "Multi-model endpoints(MME)는 단일 엔드포인트에서 수백 개의 모델을 호스팅할 수 있게 해주며, 요청이 올 때만 모델을 메모리에 로드하여 리소스를 효율적으로 공유하고 비용을 절감합니다."
    },
    {
        "question": "ML 엔지니어가 모델의 추론 성능을 테스트하기 위해 동일한 입력 데이터를 기존 모델(Production)과 새로운 모델(Candidate)에 동시에 보내려고 합니다. 실제 응답은 기존 모델의 것만 사용자에게 전달하면서 새 모델의 성능을 모니터링하는 배포 방식은 무엇입니까?",
        "options": [
            "A. Canary Deployment",
            "B. Blue/Green Deployment",
            "C. Shadow Test",
            "D. A/B Testing"
        ],
        "answer": "C",
        "explanation": "Shadow Test는 프로덕션 트래픽의 복사본을 새 모델에 보내 성능을 비교하되, 새 모델의 응답은 사용자에게 영향을 주지 않는 방식입니다. 위험 부담 없이 모델 성능을 검증하기에 가장 좋습니다."
    },
    {
        "question": "SageMaker Studio를 사용하는 개발자들의 접근 권한을 제어하고, 각 사용자별로 격리된 환경을 제공하려고 합니다. AWS IAM 외에 SageMaker 내에서 사용자 환경을 논리적으로 분리하는 단위는 무엇입니까?",
        "options": [
            "A. SageMaker Project",
            "B. User Profile",
            "C. SageMaker Domain",
            "D. Notebook Instance"
        ],
        "answer": "B",
        "explanation": "SageMaker Domain 내에서 각 사용자는 개별 User Profile을 가집니다. 이를 통해 사용자별로 고유한 전용 스토리지를 할당받고 설정을 독립적으로 관리할 수 있습니다."
    },
    {
        "question": "전처리(Preprocessing), 추론(Inference), 후처리(Post-processing) 로직이 서로 다른 컨테이너에 구현되어 있습니다. 이들을 하나의 엔드포인트로 묶어 데이터가 순차적으로 흐르도록 구성하는 방식은?",
        "options": [
            "A. Multi-model endpoints",
            "B. Inference Pipelines",
            "C. SageMaker Batch Transform",
            "D. SageMaker Clarify"
        ],
        "answer": "B",
        "explanation": "Inference Pipelines를 사용하면 2개에서 15개 사이의 컨테이너를 하나로 묶어 선형 시퀀스로 실행할 수 있습니다. 전처리와 추론 로직을 분리하여 관리하기 용이합니다."
    },
    {
        "question": "모델 학습 데이터에 주민등록번호와 같은 민감 정보(PII)가 포함되어 있는지 확인하고, 이를 자동으로 식별하여 가려주는 서비스는 무엇입니까?",
        "options": [
            "A. Amazon Macie",
            "B. Amazon GuardDuty",
            "C. AWS Shield",
            "D. Amazon Inspector"
        ],
        "answer": "A",
        "explanation": "Amazon Macie는 머신러닝과 패턴 매칭을 사용하여 S3에 저장된 민감한 데이터를 자동으로 감지하고 보호하는 보안 서비스입니다."
    },
    {
        "question": "SageMaker 엔드포인트의 호출 로그 및 추론 데이터를 분석하여 나중에 재학습(Retraining) 데이터로 활용하려고 합니다. 엔드포인트로 들어오는 모든 요청과 응답 데이터를 S3로 자동으로 캡처하는 기능은 무엇입니까?",
        "options": [
            "A. SageMaker Model Monitor",
            "B. SageMaker Data Capture",
            "C. CloudWatch Logs",
            "D. AWS CloudTrail"
        ],
        "answer": "B",
        "explanation": "SageMaker Data Capture 기능을 활성화하면 실시간 엔드포인트로 들어오는 입력 데이터와 모델의 예측 결과를 지정된 S3 버킷에 자동으로 저장합니다."
    },
    {
        "question": "모바일 기기나 IoT 장치와 같은 엣지 디바이스에서 모델을 실행하기 위해, 하드웨어에 최적화된 형태로 모델을 컴파일하고 패키징하는 서비스는 무엇입니까?",
        "options": [
            "A. SageMaker Neo",
            "B. SageMaker Edge Manager",
            "C. AWS RoboMaker",
            "D. SageMaker Ground Truth"
        ],
        "answer": "A",
        "explanation": "SageMaker Neo는 모델을 특정 하드웨어 타겟에 맞춰 최적화(컴파일)하여 성능을 최대 25배 향상시키고 용량을 줄여줍니다."
    },
    {
        "question": "기업 내에서 모델 개발 프로세스의 거버넌스를 강화하기 위해, 모델의 생성부터 배포까지의 모든 이력(Lineage)을 추적하고 싶습니다. 이를 확인하는 가장 적합한 도구는?",
        "options": [
            "A. SageMaker Model Registry",
            "B. SageMaker ML Lineage Tracking",
            "C. AWS Config",
            "D. Amazon SageMaker Studio 노트북"
        ],
        "answer": "B",
        "explanation": "ML Lineage Tracking은 데이터 원천, 학습 작업, 파이프라인 실행 등 ML 워크플로의 모든 아티팩트 간 관계를 기록하여 재현성과 투명성을 제공합니다."
    },
    {
        "question": "추론 요청의 크기가 매우 크고(예: 고해상도 이미지), 응답 시간이 최대 15분까지 소요될 수 있는 경우 가장 적합한 SageMaker 추론 옵션은?",
        "options": [
            "A. Real-time Inference",
            "B. Serverless Inference",
            "C. Asynchronous Inference",
            "D. Batch Transform"
        ],
        "answer": "C",
        "explanation": "Asynchronous Inference는 최대 1GB의 페이로드 크기와 최대 1시간의 처리 시간을 지원하며, 요청을 큐(Queue)에 쌓아두고 처리하는 방식에 적합합니다."
    },
    {
        "question": "SageMaker 인스턴스에서 실행되는 모든 API 호출 내역을 감사(Auditing)하고 기록하여 보안 규정 준수를 증명해야 합니다. 어떤 서비스를 사용해야 합니까?",
        "options": [
            "A. Amazon CloudWatch",
            "B. AWS CloudTrail",
            "C. AWS IAM",
            "D. AWS Artifact"
        ],
        "answer": "B",
        "explanation": "AWS CloudTrail은 SageMaker API를 포함한 모든 AWS 계정 내 활동을 기록하여 거버넌스, 규정 준수 및 위험 감사를 지원합니다."
    },
    {
        "question": "분산 학습을 수행할 때 데이터 병렬화(Data Parallelism)를 적용하려고 합니다. 각 워커 노드가 전체 모델의 복사본을 가지고 있고, 데이터를 나누어 학습한 뒤 기울기(Gradients)를 동기화하는 가장 효율적인 SageMaker 내장 라이브러리는?",
        "options": [
            "A. SageMaker Model Parallel (SMMP)",
            "B. SageMaker Data Parallel (SMDDP)",
            "C. Horovod",
            "D. Parameter Server"
        ],
        "answer": "B",
        "explanation": "SageMaker Data Parallel(SMDDP)은 AWS 네트워크 인프라에 최적화되어 데이터 병렬 학습 시 통신 오버헤드를 줄이고 처리량을 최대화합니다."
    },
    {
        "question": "Amazon SageMaker 노트북에서 작업 중인 데이터 과학자가 대용량 파일을 S3에서 로컬로 다운로드하지 않고도 파일 탐색기처럼 접근하여 읽고 싶어 합니다. 어떤 설정이 가장 적합합니까?",
        "options": [
            "A. S3 Transfer Acceleration 사용",
            "B. FSx for Lustre를 사용하여 S3와 동기화",
            "C. SageMaker Fast File Mode 사용",
            "D. AWS Glue Data Catalog 연동"
        ],
        "answer": "C",
        "explanation": "Fast File Mode를 사용하면 S3 데이터를 로컬 파일 시스템에 마운트한 것처럼 사용할 수 있어 다운로드 시간 없이 즉시 데이터에 접근할 수 있습니다."
    },
    {
        "question": "모델 학습 중 특정 에포크(Epoch)에서 검증 정확도가 더 이상 향상되지 않을 때, 학습을 자동으로 종료하여 컴퓨팅 자원을 절약하고 과적합(Overfitting)을 방지하는 방법은 무엇입니까?",
        "options": [
            "A. Hyperparameter Tuning의 Early Stopping",
            "B. SageMaker Debugger의 내장 Rule",
            "C. 모델 체크포인트 삭제",
            "D. CloudWatch Alarm을 통한 인스턴스 종료"
        ],
        "answer": "B",
        "explanation": "SageMaker Debugger는 학습 도중 지표를 모니터링하다가 과적합이나 정확도 정체 현상이 발생하면 자동으로 학습 작업을 중단시키는 내장 규칙을 제공합니다."
    },
    {
        "question": "훈련 데이터 세트의 품질을 확인하기 위해 데이터의 통계적 요약(평균, 표준편차 등)을 생성하고, 데이터 스키마가 의도한 대로인지 검증하는 데 가장 적합한 라이브러리 또는 기능은?",
        "options": [
            "A. SageMaker Model Monitor",
            "B. SageMaker Clarify",
            "C. Amazon Deequ",
            "D. AWS Glue DataBrew"
        ],
        "answer": "C",
        "explanation": "Amazon Deequ는 대규모 데이터 세트의 품질을 정의하고 검증하기 위한 오픈 소스 라이브러리(Spark 기반)로, AWS 환경에서 데이터 유효성 검사 시 널리 사용됩니다."
    },
    {
        "question": "학습에 사용되는 EC2 인스턴스의 로컬 디스크 공간이 부족하여 대용량 데이터 세트를 처리하지 못하고 있습니다. EBS 볼륨을 수동으로 늘리지 않고 해결할 수 있는 가장 관리 효율적인 방법은?",
        "options": [
            "A. 인스턴스 유형을 더 큰 사양으로 변경",
            "B. Amazon EFS(Elastic File System) 마운트",
            "C. S3에서 데이터를 조각내어 순차적으로 다운로드",
            "D. SageMaker Pipe Mode 사용"
        ],
        "answer": "D",
        "explanation": "Pipe Mode는 데이터를 로컬 디스크에 저장하지 않고 S3에서 인스턴스로 직접 스트리밍하므로 디스크 공간 제약을 극복할 수 있습니다."
    },
    {
        "question": "추론 요청의 처리량(Throughput)을 높이기 위해 동일한 인스턴스 내에서 여러 모델 복사본을 실행하여 병렬 처리를 극대화하고 싶습니다. 엔드포인트 설정에서 조정해야 할 파라미터는?",
        "options": [
            "A. InstanceCount",
            "B. InitialVariantWeight",
            "C. AcceleratorType",
            "D. ModelDataDownloadTimeoutInSeconds"
        ],
        "answer": "A",
        "explanation": "InstanceCount를 늘리면 여러 인스턴스에 모델이 배포되어 전체 처리량이 증가합니다. (참고: 단일 인스턴스 내 병렬 처리는 컨테이너 설정이나 환경 변수로 조절할 수 있습니다.)"
    },
    {
        "question": "SageMaker Studio 노트북에서 대규모 데이터 처리를 위해 Spark 클러스터가 필요합니다. 별도의 클러스터를 수동으로 구축하지 않고 노트북 내에서 바로 Spark 작업을 실행할 수 있는 기능은?",
        "options": [
            "A. SageMaker Processing with PySpark",
            "B. Amazon EMR 노트북",
            "C. Glue 인터랙티브 세션",
            "D. SageMaker Studio의 내장 이미지 (Spark용)"
        ],
        "answer": "A",
        "explanation": "SageMaker Processing은 PySpark 전용 컨테이너 이미지를 제공하여 관리형 인스턴스에서 분산 Spark 작업을 간편하게 실행할 수 있게 해줍니다."
    },
    {
        "question": "모델의 학습 코드나 아티팩트는 변경되지 않았지만, 입력되는 실제 데이터의 분포가 학습 당시와 달라져 성능이 떨어지는 현상을 무엇이라 합니까?",
        "options": [
            "A. Concept Drift",
            "B. Data Drift",
            "C. Model Bias",
            "D. Label Leakage"
        ],
        "answer": "B",
        "explanation": "데이터 드리프트(Data Drift)는 입력 데이터의 통계적 성질이 변하는 현상을 의미합니다. (참고: 입력과 타겟 레이블 간의 관계가 변하는 것은 Concept Drift입니다.)"
    },
    {
        "question": "ML 엔지니어가 비용 효율적인 추론을 위해 FP32(32비트 부동 소수점) 모델을 INT8(8비트 정수)로 변환하여 지연 시간을 줄이고자 합니다. 이 프로세스와 관련이 깊은 기능은?",
        "options": [
            "A. SageMaker Neo",
            "B. SageMaker Clarify",
            "C. SageMaker Model Registry",
            "D. SageMaker Debugger"
        ],
        "answer": "A",
        "explanation": "SageMaker Neo는 모델 양자화(Quantization) 및 컴파일을 통해 타겟 하드웨어에 최적화된 저지연/고효율 모델을 생성합니다."
    },
    {
        "question": "동일한 S3 버킷 내의 데이터를 여러 SageMaker 학습 작업이 동시에 읽어야 할 때, 읽기 성능 병목을 방지하기 위한 S3의 모범 사례는 무엇입니까?",
        "options": [
            "A. 데이터를 여러 리전에 복제",
            "B. S3 버킷에 대한 버전 관리 비활성화",
            "C. 객체 키 이름에 무작위 접두사(Prefix)를 사용하여 파티셔닝",
            "D. 모든 데이터를 단일 대형 파일로 통합"
        ],
        "answer": "C",
        "explanation": "S3는 접두사를 기준으로 초당 요청 수를 제한하므로, 키 구조를 다양하게 설계하면 성능 병목을 줄이고 높은 처리량을 얻을 수 있습니다."
    },
    {
        "question": "분산 학습을 수행할 때 데이터 병렬화(Data Parallelism)를 적용하려고 합니다. 각 워커 노드가 전체 모델의 복사본을 가지고 있고, 데이터를 나누어 학습한 뒤 기울기(Gradients)를 동기화하는 가장 효율적인 SageMaker 내장 라이브러리는?",
        "options": [
            "A. SageMaker Model Parallel (SMMP)",
            "B. SageMaker Data Parallel (SMDDP)",
            "C. Horovod",
            "D. Parameter Server"
        ],
        "answer": "B",
        "explanation": "SageMaker Data Parallel(SMDDP)은 AWS 네트워크 인프라에 최적화되어 데이터 병렬 학습 시 통신 오버헤드를 줄이고 처리량을 최대화합니다."
    },
    {
        "question": "Amazon SageMaker 노트북에서 작업 중인 데이터 과학자가 대용량 파일을 S3에서 로컬로 다운로드하지 않고도 파일 탐색기처럼 접근하여 읽고 싶어 합니다. 어떤 설정이 가장 적합합니까?",
        "options": [
            "A. S3 Transfer Acceleration 사용",
            "B. FSx for Lustre를 사용하여 S3와 동기화",
            "C. SageMaker Fast File Mode 사용",
            "D. AWS Glue Data Catalog 연동"
        ],
        "answer": "C",
        "explanation": "Fast File Mode를 사용하면 S3 데이터를 로컬 파일 시스템에 마운트한 것처럼 사용할 수 있어 다운로드 시간 없이 즉시 데이터에 접근할 수 있습니다."
    },
    {
        "question": "모델 학습 중 특정 에포크(Epoch)에서 검증 정확도가 더 이상 향상되지 않을 때, 학습을 자동으로 종료하여 컴퓨팅 자원을 절약하고 과적합(Overfitting)을 방지하는 방법은 무엇입니까?",
        "options": [
            "A. Hyperparameter Tuning의 Early Stopping",
            "B. SageMaker Debugger의 내장 Rule",
            "C. 모델 체크포인트 삭제",
            "D. CloudWatch Alarm을 통한 인스턴스 종료"
        ],
        "answer": "B",
        "explanation": "SageMaker Debugger는 학습 도중 지표를 모니터링하다가 과적합이나 정확도 정체 현상이 발생하면 자동으로 학습 작업을 중단시키는 내장 규칙을 제공합니다."
    },
    {
        "question": "훈련 데이터 세트의 품질을 확인하기 위해 데이터의 통계적 요약(평균, 표준편차 등)을 생성하고, 데이터 스키마가 의도한 대로인지 검증하는 데 가장 적합한 라이브러리 또는 기능은?",
        "options": [
            "A. SageMaker Model Monitor",
            "B. SageMaker Clarify",
            "C. Amazon Deequ",
            "D. AWS Glue DataBrew"
        ],
        "answer": "C",
        "explanation": "Amazon Deequ는 대규모 데이터 세트의 품질을 정의하고 검증하기 위한 오픈 소스 라이브러리(Spark 기반)로, AWS 환경에서 데이터 유효성 검사 시 널리 사용됩니다."
    },
    {
        "question": "학습에 사용되는 EC2 인스턴스의 로컬 디스크 공간이 부족하여 대용량 데이터 세트를 처리하지 못하고 있습니다. EBS 볼륨을 수동으로 늘리지 않고 해결할 수 있는 가장 관리 효율적인 방법은?",
        "options": [
            "A. 인스턴스 유형을 더 큰 사양으로 변경",
            "B. Amazon EFS(Elastic File System) 마운트",
            "C. S3에서 데이터를 조각내어 순차적으로 다운로드",
            "D. SageMaker Pipe Mode 사용"
        ],
        "answer": "D",
        "explanation": "Pipe Mode는 데이터를 로컬 디스크에 저장하지 않고 S3에서 인스턴스로 직접 스트리밍하므로 디스크 공간 제약을 극복할 수 있습니다."
    },
    {
        "question": "추론 요청의 처리량(Throughput)을 높이기 위해 동일한 인스턴스 내에서 여러 모델 복사본을 실행하여 병렬 처리를 극대화하고 싶습니다. 엔드포인트 설정에서 조정해야 할 파라미터는?",
        "options": [
            "A. InstanceCount",
            "B. InitialVariantWeight",
            "C. AcceleratorType",
            "D. ModelDataDownloadTimeoutInSeconds"
        ],
        "answer": "A",
        "explanation": "InstanceCount를 늘리면 여러 인스턴스에 모델이 배포되어 전체 처리량이 증가합니다. (참고: 단일 인스턴스 내 병렬 처리는 컨테이너 설정이나 환경 변수로 조절할 수 있습니다.)"
    },
    {
        "question": "SageMaker Studio 노트북에서 대규모 데이터 처리를 위해 Spark 클러스터가 필요합니다. 별도의 클러스터를 수동으로 구축하지 않고 노트북 내에서 바로 Spark 작업을 실행할 수 있는 기능은?",
        "options": [
            "A. SageMaker Processing with PySpark",
            "B. Amazon EMR 노트북",
            "C. Glue 인터랙티브 세션",
            "D. SageMaker Studio의 내장 이미지 (Spark용)"
        ],
        "answer": "A",
        "explanation": "SageMaker Processing은 PySpark 전용 컨테이너 이미지를 제공하여 관리형 인스턴스에서 분산 Spark 작업을 간편하게 실행할 수 있게 해줍니다."
    },
    {
        "question": "모델의 학습 코드나 아티팩트는 변경되지 않았지만, 입력되는 실제 데이터의 분포가 학습 당시와 달라져 성능이 떨어지는 현상을 무엇이라 합니까?",
        "options": [
            "A. Concept Drift",
            "B. Data Drift",
            "C. Model Bias",
            "D. Label Leakage"
        ],
        "answer": "B",
        "explanation": "데이터 드리프트(Data Drift)는 입력 데이터의 통계적 성질이 변하는 현상을 의미합니다. (참고: 입력과 타겟 레이블 간의 관계가 변하는 것은 Concept Drift입니다.)"
    },
    {
        "question": "ML 엔지니어가 비용 효율적인 추론을 위해 FP32(32비트 부동 소수점) 모델을 INT8(8비트 정수)로 변환하여 지연 시간을 줄이고자 합니다. 이 프로세스와 관련이 깊은 기능은?",
        "options": [
            "A. SageMaker Neo",
            "B. SageMaker Clarify",
            "C. SageMaker Model Registry",
            "D. SageMaker Debugger"
        ],
        "answer": "A",
        "explanation": "SageMaker Neo는 모델 양자화(Quantization) 및 컴파일을 통해 타겟 하드웨어에 최적화된 저지연/고효율 모델을 생성합니다."
    },
    {
        "question": "동일한 S3 버킷 내의 데이터를 여러 SageMaker 학습 작업이 동시에 읽어야 할 때, 읽기 성능 병목을 방지하기 위한 S3의 모범 사례는 무엇입니까?",
        "options": [
            "A. 데이터를 여러 리전에 복제",
            "B. S3 버킷에 대한 버전 관리 비활성화",
            "C. 객체 키 이름에 무작위 접두사(Prefix)를 사용하여 파티셔닝",
            "D. 모든 데이터를 단일 대형 파일로 통합"
        ],
        "answer": "C",
        "explanation": "S3는 접두사를 기준으로 초당 요청 수를 제한하므로, 키 구조를 다양하게 설계하면 성능 병목을 줄이고 높은 처리량을 얻을 수 있습니다."
    },
    {
        "question": "한 회사에서 수천 명의 외부 작업자를 통해 이미지 데이터 레이블링을 진행하려고 합니다. 작업자에게 민감한 데이터가 노출되지 않도록 제어하고, 레이블링 품질을 보장하기 위해 여러 명의 작업 결과를 비교하는 기능이 포함된 서비스는 무엇입니까?",
        "options": [
            "A. SageMaker Ground Truth Plus",
            "B. SageMaker Clarify",
            "C. SageMaker Data Wrangler",
            "D. Amazon Mechanical Turk"
        ],
        "answer": "A",
        "explanation": "SageMaker Ground Truth 및 Ground Truth Plus는 데이터 레이블링 워크플로를 관리하며, 품질 검증 로직과 작업자 권한 제어 기능을 제공합니다."
    },
    {
        "question": "ML 엔지니어가 SageMaker Studio 내에서 코드를 거의 작성하지 않고 시각적인 인터페이스만으로 데이터를 탐색, 정리 및 변환(ETL)하고자 합니다. 이 요구사항에 가장 적합한 기능은?",
        "options": [
            "A. SageMaker Processing",
            "B. SageMaker Data Wrangler",
            "C. AWS Glue DataBrew",
            "D. SageMaker Autopilot"
        ],
        "answer": "B",
        "explanation": "SageMaker Data Wrangler는 ML을 위한 데이터 준비 과정을 간소화하는 시각적 도구로, 300개 이상의 내장 데이터 변환 기능을 제공합니다."
    },
    {
        "question": "SageMaker Feature Store의 '오프라인 저장소(Offline Store)'는 주로 어떤 용도로 사용되며, 데이터는 어디에 저장됩니까?",
        "options": [
            "A. 실시간 추론을 위한 저지연 읽기용, Amazon DynamoDB",
            "B. 배치 추론 및 모델 학습을 위한 과거 데이터 저장용, Amazon S3",
            "C. 모델 아티팩트 보관용, Amazon EFS",
            "D. 로그 분석용, Amazon OpenSearch"
        ],
        "answer": "B",
        "explanation": "오프라인 저장소는 대량의 과거 특성 데이터를 S3에 저장하여 모델 학습이나 배치 추론 시 사용하며, 온라인 저장소는 실시간 추론을 위해 사용됩니다."
    },
    {
        "question": "모델의 특정 버전이 프로덕션 환경에 배포되기 전에 반드시 담당자의 수동 승인(Manual Approval)을 거치도록 설정하려고 합니다. 이를 위해 사용해야 하는 서비스 조합은?",
        "options": [
            "A. SageMaker Model Registry와 SageMaker Pipelines",
            "B. SageMaker Studio와 AWS CloudTrail",
            "C. SageMaker Clarify와 Amazon SNS",
            "D. SageMaker Neo와 AWS Lambda"
        ],
        "answer": "A",
        "explanation": "SageMaker Model Registry에서 모델 상태를 'Pending'으로 두고, 승인자가 이를 'Approved'로 변경하면 파이프라인이 배포를 시작하도록 구성할 수 있습니다."
    },
    {
        "question": "SageMaker 학습 작업 중 '인스턴스 간 통신(Inter-node communication)' 속도를 높이기 위해 AWS에서 제공하는 전용 네트워크 인터페이스는 무엇입니까?",
        "options": [
            "A. Elastic Network Interface (ENI)",
            "B. Elastic Fabric Adapter (EFA)",
            "C. Virtual Private Gateway",
            "D. AWS Direct Connect"
        ],
        "answer": "B",
        "explanation": "EFA는 고성능 컴퓨팅(HPC) 및 ML 학습 작업을 위해 설계된 네트워크 장치로, 노드 간 통신 지연 시간을 줄여 분산 학습 성능을 높입니다."
    },
    {
        "question": "이미 학습된 모델의 가중치를 고정하고, 새로운 데이터 세트에 맞게 마지막 레이어만 다시 학습시키는 기법을 무엇이라 합니까? (SageMaker JumpStart에서 주로 활용됨)",
        "options": [
            "A. Hyperparameter Optimization",
            "B. Transfer Learning (전이 학습)",
            "C. Active Learning",
            "D. Reinforcement Learning"
        ],
        "answer": "B",
        "explanation": "전이 학습은 기존에 잘 학습된 모델의 지식을 새로운 유사 작업에 재사용하는 기법으로, 적은 데이터로도 높은 성능을 낼 수 있습니다."
    },
    {
        "question": "SageMaker 엔드포인트에 오토스케일링(Autoscaling)을 적용하려고 합니다. 트래픽의 변화에 따라 인스턴스 수를 조절하기 위해 가장 흔히 사용되는 CloudWatch 지표는 무엇입니까?",
        "options": [
            "A. CPUUtilization",
            "B. InvocationsPerInstance",
            "C. ModelLatency",
            "D. MemoryUtilization"
        ],
        "answer": "B",
        "explanation": "InvocationsPerInstance 지표는 인스턴스당 요청 수를 나타내며, 추론 요청량 변화에 따라 인스턴스를 확장/축소하기에 가장 적합한 지표입니다."
    },
    {
        "question": "SageMaker Studio의 모든 트래픽이 공용 인터넷을 거치지 않도록 설정하고 싶습니다. 이를 위해 사용해야 하는 VPC 인터페이스 엔드포인트가 아닌 것은?",
        "options": [
            "A. SageMaker API 엔드포인트",
            "B. SageMaker Runtime 엔드포인트",
            "C. S3 Gateway 엔드포인트",
            "D. Amazon EC2 엔드포인트"
        ],
        "answer": "D",
        "explanation": "SageMaker 환경 보안을 위해서는 API, Runtime, S3 엔드포인트가 필수적이나, EC2 엔드포인트는 SageMaker Studio의 보안 접속 자체와는 직접적인 상관이 없습니다."
    },
    {
        "question": "모델 배포 후, 모델이 예측한 값과 실제 결과값(Ground Truth)을 비교하여 정확도 지표를 지속적으로 계산하고 시각화해주는 기능은?",
        "options": [
            "A. SageMaker Model Monitor (Model Quality)",
            "B. SageMaker Debugger",
            "C. SageMaker Clarify",
            "D. SageMaker Lineage Tracking"
        ],
        "answer": "A",
        "explanation": "Model Monitor의 Model Quality 모니터링은 실제 라벨 데이터와 예측 데이터를 비교하여 정확도, 정밀도 등의 지표 변화를 추적합니다."
    },
    {
        "question": "SageMaker Training Job 실행 시, 학습 코드가 포함된 Docker 이미지를 저장하고 관리하는 서비스는?",
        "options": [
            "A. Amazon ECR (Elastic Container Registry)",
            "B. Amazon S3",
            "C. AWS CodeCommit",
            "D. Amazon EBS"
        ],
        "answer": "A",
        "explanation": "SageMaker는 학습 및 추론에 필요한 Docker 이미지를 Amazon ECR에서 가져와 컨테이너를 실행합니다."
    },
    {
        "question": "한 보안 지침에 따라 SageMaker 학습 인스턴스가 퍼블릭 인터넷에 접속하는 것을 엄격히 금지해야 합니다. 동시에 S3에 저장된 학습 데이터에는 접근할 수 있어야 합니다. 이를 위한 올바른 VPC 구성은 무엇입니까?",
        "options": [
            "A. 인스턴스를 퍼블릭 서브넷에 배치하고 0.0.0.0/0 아웃바운드 규칙을 허용한다.",
            "B. 인스턴스를 프라이빗 서브넷에 배치하고 S3용 인터페이스 VPC 엔드포인트를 생성한다.",
            "C. 인스턴스를 프라이빗 서브넷에 배치하고 S3용 게이트웨이 VPC 엔드포인트를 생성하며, Network isolation 모드를 활성화한다.",
            "D. NAT Gateway를 통해 모든 트래픽을 S3로 보낸다."
        ],
        "answer": "C",
        "explanation": "SageMaker 학습 작업에서 'Network isolation'을 활성화하면 컨테이너의 네트워크 호출이 차단됩니다. 이때 S3 접근을 위해서는 VPC 내부의 게이트웨이 엔드포인트를 이용해야 보안 정책을 완벽히 준수할 수 있습니다."
    },
    {
        "question": "SageMaker 엔드포인트에 오토스케일링을 설정할 때, 트래픽이 갑자기 급증했다가 다시 급격히 감소하는 환경입니다. 불필요한 인스턴스 유지를 최소화하기 위해 조정해야 하는 설정 값은 무엇입니까?",
        "options": [
            "A. Scale-in cooldown period",
            "B. Scale-out cooldown period",
            "C. Target value",
            "D. Maximum capacity"
        ],
        "answer": "A",
        "explanation": "Scale-in cooldown(축소 대기 시간)은 인스턴스 숫자를 줄이기 전 기다리는 시간입니다. 비용 최적화를 위해 이 값을 낮추면 트래픽 감소 시 더 빠르게 인스턴스를 제거할 수 있습니다."
    },
    {
        "question": "Amazon SageMaker Studio 노트북 내에서 데이터베이스 자격 증명(ID/PW)을 하드코딩하지 않고 안전하게 관리하여 데이터베이스에 연결하고 싶습니다. 어떤 서비스를 연동해야 합니까?",
        "options": [
            "A. AWS IAM",
            "B. AWS Secrets Manager",
            "C. Amazon Cognito",
            "D. AWS Key Management Service (KMS)"
        ],
        "answer": "B",
        "explanation": "Secrets Manager는 데이터베이스 인증 정보와 같은 민감한 자격 증명을 안전하게 저장하고, API를 통해 동적으로 로드할 수 있게 해줍니다."
    },
    {
        "question": "ML 엔지니어가 대규모 데이터 세트를 처리하기 위해 Amazon EMR 클러스터를 사용하고 있습니다. EMR에서 처리된 데이터를 SageMaker 학습 인스턴스에서 가장 지연 시간이 적게 읽어오기 위해 공유할 수 있는 스토리지 서비스는?",
        "options": [
            "A. Amazon EFS",
            "B. Amazon S3",
            "C. Amazon FSx for Lustre",
            "D. Amazon EBS"
        ],
        "answer": "C",
        "explanation": "FSx for Lustre는 S3와 연동되는 고성능 파일 시스템으로, EMR과 SageMaker 모두에서 초고속으로 접근 가능하여 대규모 데이터 처리 및 학습에 최적입니다."
    },
    {
        "question": "SageMaker에서 모델 학습을 수행할 때, 여러 개의 S3 버킷에 분산된 데이터를 하나의 통합된 데이터 세트로 참조하게 해주는 기능은?",
        "options": [
            "A. S3 Inventory",
            "B. Amazon SageMaker Data Wrangler",
            "C. Augmented Manifest Files",
            "D. S3 Batch Operations"
        ],
        "answer": "C",
        "explanation": "Augmented Manifest Files를 사용하면 여러 위치에 있는 데이터의 경로와 레이블 정보를 JSON 라인 형식으로 기록하여 하나의 데이터 입력 스트림으로 사용할 수 있습니다."
    },
    {
        "question": "SageMaker 추론 엔드포인트가 특정 IAM 역할(Role)에 의해서만 호출될 수 있도록 제한하고 싶습니다. 이를 제어하는 가장 올바른 방법은?",
        "options": [
            "A. 엔드포인트 컨테이너 내부에 보안 코드를 작성한다.",
            "B. 엔드포인트에 대한 IAM Identity-based Policy를 생성하여 'sagemaker:InvokeEndpoint' 권한을 제어한다.",
            "C. VPC 보안 그룹(Security Group)에서 포트 80을 차단한다.",
            "D. API Gateway를 앞에 두고 Lambda Authorizer를 사용한다."
        ],
        "answer": "B",
        "explanation": "AWS의 표준 보안 방식은 IAM 정책을 통해 특정 주체(User/Role)가 특정 리소스(Endpoint)의 API를 호출할 권한이 있는지 제어하는 것입니다."
    },
    {
        "question": "모델의 여러 버전을 SageMaker Model Registry에 등록할 때, 각 버전의 메타데이터(정확도 지표, 생성 날짜 등)를 자동으로 기록하고 관리하는 서비스는?",
        "options": [
            "A. SageMaker Studio",
            "B. SageMaker Model Registry",
            "C. AWS Config",
            "D. Amazon EventBridge"
        ],
        "answer": "B",
        "explanation": "Model Registry는 모델 버전을 중앙에서 관리하며, 각 모델의 성능 지표와 승인 상태 등을 메타데이터로 기록하여 관리 효율성을 높입니다."
    },
    {
        "question": "SageMaker Studio 인스턴스가 시작될 때마다 특정 라이브러리를 자동으로 설치하거나 환경 설정을 수행하고 싶습니다. 어떤 기능을 사용해야 합니까?",
        "options": [
            "A. AWS Lambda",
            "B. Lifecycle Configurations",
            "C. User Data Scripts",
            "D. SageMaker Projects"
        ],
        "answer": "B",
        "explanation": "Lifecycle Configurations(수명 주기 구성) 스크립트를 사용하면 노트북 인스턴스나 스튜디오 앱이 시작될 때 실행될 쉘 스크립트를 지정할 수 있습니다."
    },
    {
        "question": "딥러닝 모델 학습 중 'Graident Explosion' 문제를 감지하고 알림을 보내고 싶습니다. 어떤 도구가 가장 적절합니까?",
        "options": [
            "A. SageMaker Clarify",
            "B. SageMaker Debugger",
            "C. Amazon Managed Grafana",
            "D. AWS X-Ray"
        ],
        "answer": "B",
        "explanation": "SageMaker Debugger는 학습 도중 텐서 값을 모니터링하여 기울기 폭주(Gradient Explosion)와 같은 수치적 불안정성을 감지하는 내장 규칙을 제공합니다."
    },
    {
        "question": "SageMaker에서 대규모 언어 모델(LLM)을 학습시키기 위해 모델 가중치를 여러 GPU에 나누어 배치해야 합니다. 이때 사용해야 하는 병렬화 전략은?",
        "options": [
            "A. Data Parallelism",
            "B. Model Parallelism",
            "C. Instance Parallelism",
            "D. Task Parallelism"
        ],
        "answer": "B",
        "explanation": "모델의 크기가 너무 커서 단일 GPU의 메모리에 담기지 않을 경우, 모델의 레이어나 파라미터를 여러 GPU에 나누는 'Model Parallelism(모델 병렬화)'이 필수적입니다."
    },
    {
        "question": "ML 엔지니어가 수백 기가바이트의 원시 데이터를 처리하여 학습용 데이터 세트를 만들려고 합니다. 대규모 분산 처리가 필요하지만 고정된 인프라를 유지하고 싶지는 않습니다. Python 스크립트를 사용하여 일시적으로 클러스터를 띄워 데이터를 처리하고 자동 종료되는 SageMaker 기능은 무엇입니까?",
        "options": [
            "A. SageMaker Training Jobs",
            "B. SageMaker Processing Jobs",
            "C. SageMaker Notebook Instances",
            "D. SageMaker Serverless Inference"
        ],
        "answer": "B",
        "explanation": "SageMaker Processing은 데이터 전처리, 후처리 및 모델 평가 작업을 위해 완전히 관리되는 인프라를 제공합니다. 작업이 완료되면 컴퓨팅 리소스가 자동으로 종료되어 비용 효율적입니다."
    },
    {
        "question": "SageMaker 엔드포인트에서 추론 중 발생하는 '모델 지연 시간(Model Latency)'과 '오버헤드 지연 시간(Overhead Latency)'을 구분하여 모니터링하고 싶습니다. 이 지표들은 어디에서 확인할 수 있습니까?",
        "options": [
            "A. SageMaker Studio 통합 대시보드",
            "B. Amazon CloudWatch Metrics",
            "C. AWS CloudTrail Logs",
            "D. S3 Data Capture 파일"
        ],
        "answer": "B",
        "explanation": "SageMaker는 엔드포인트 성능과 관련된 상세 지표(Latencies, CPU/Memory 활용률 등)를 실시간으로 Amazon CloudWatch에 게시합니다."
    },
    {
        "question": "매우 큰 모델을 배포해야 하지만, 실시간 응답이 필요하지 않으며 하루에 한 번만 대량의 데이터를 한꺼번에 추론하면 됩니다. 가장 비용 효율적인 배포 전략은?",
        "options": [
            "A. Real-time Inference 엔드포인트를 상시 가동한다.",
            "B. SageMaker Batch Transform을 사용한다.",
            "C. Asynchronous Inference를 사용하고 인스턴스를 1개로 유지한다.",
            "D. Serverless Inference를 사용하여 콜드 스타트를 감수한다."
        ],
        "answer": "B",
        "explanation": "Batch Transform은 대규모 데이터 세트에 대한 비실시간 추론에 최적화되어 있습니다. 작업이 실행될 때만 인스턴스가 프로비저닝되고 완료 후 종료되므로 비용이 가장 저렴합니다."
    },
    {
        "question": "SageMaker Studio 노트북을 사용 중인 팀원이 실수로 중요한 데이터를 삭제하는 것을 방지하기 위해, 특정 S3 버킷에 대해서는 읽기 전용 권한만 부여하려고 합니다. 무엇을 수정해야 합니까?",
        "options": [
            "A. 노트북 인스턴스의 보안 그룹(Security Group)",
            "B. 사용자의 IAM 실행 역할(Execution Role) 정책",
            "C. SageMaker 도메인의 VPC 설정",
            "D. S3 버킷의 ACL 설정"
        ],
        "answer": "B",
        "explanation": "SageMaker 서비스가 사용자 대신 AWS 리소스에 액세스할 때는 '실행 역할(Execution Role)'을 사용합니다. 이 역할에 연결된 IAM 정책에서 S3 접근 권한을 제한해야 합니다."
    },
    {
        "question": "텐서플로(TensorFlow)로 작성된 기존 학습 코드를 수정하지 않고 SageMaker에서 실행하고 싶습니다. SageMaker에서 제공하는 표준 프레임워크 컨테이너를 사용하는 방식을 무엇이라 합니까?",
        "options": [
            "A. Built-in Algorithms",
            "B. Script Mode",
            "C. Docker Container Mode",
            "D. SageMaker Autopilot"
        ],
        "answer": "B",
        "explanation": "Script Mode를 사용하면 사용자가 작성한 표준 Python 스크립트를 전달하기만 하면 SageMaker가 해당 프레임워크(TF, PyTorch 등) 전용 컨테이너에서 코드를 실행해줍니다."
    },
    {
        "question": "모델 학습 시 하이퍼파라미터 조합을 탐색하는 시간을 단축하기 위해, 이전 튜닝 작업의 결과를 활용하여 검색을 시작하는 기능은 무엇입니까?",
        "options": [
            "A. Warm Start",
            "B. Grid Search",
            "C. Random Search",
            "D. Early Stopping"
        ],
        "answer": "A",
        "explanation": "Warm Start 기능을 사용하면 이전 하이퍼파라미터 튜닝 작업(HPO)에서 얻은 지식을 재사용하여 새로운 튜닝 작업의 효율성을 높이고 시간을 단축할 수 있습니다."
    },
    {
        "question": "학습 작업이 완료된 후 모델 아티팩트(.tar.gz)가 저장되는 기본 위치는 어디입니까?",
        "options": [
            "A. Amazon EBS 볼륨",
            "B. SageMaker Studio 로컬 디렉토리",
            "C. Amazon S3",
            "D. Amazon ECR"
        ],
        "answer": "C",
        "explanation": "SageMaker 학습 작업의 결과물인 모델 아티팩트는 작업 설정 시 지정한 S3 버킷 경로에 저장됩니다."
    },
    {
        "question": "SageMaker Pipelines를 구성할 때, 이전 단계의 출력값(예: 학습된 모델의 S3 경로)을 다음 단계의 입력값으로 전달하기 위해 사용하는 객체는?",
        "options": [
            "A. Pipeline Parameters",
            "B. Property Files",
            "C. Pipeline Variables",
            "D. Step Outputs"
        ],
        "answer": "B",
        "explanation": "Property Files를 사용하면 한 단계(예: Processing step)에서 생성된 JSON 파일의 특정 값을 파이프라인의 다음 단계에서 조건부 로직이나 입력값으로 활용할 수 있습니다."
    },
    {
        "question": "SageMaker Clarify를 사용하여 모델의 개별 예측 결과에 대해 각 특성이 얼마나 기여했는지 분석하려고 합니다. 이때 사용되는 알고리즘은 무엇입니까?",
        "options": [
            "A. XGBoost",
            "B. Linear Learner",
            "C. SHAP (Shapley Additive Explanations)",
            "D. K-Means"
        ],
        "answer": "C",
        "explanation": "SageMaker Clarify는 커널 SHAP 알고리즘을 사용하여 모델의 특정 예측 결과에 대한 각 입력 특성의 기여도를 계산(설명 가능성 제공)합니다."
    },
    {
        "question": "관리자가 SageMaker Studio 사용자들에게 공통적으로 제공할 환경(예: 특정 라이브러리가 미리 설치된 R 전용 환경)을 구성하기 위해 커스텀 이미지를 생성했습니다. 이 이미지는 어디에 등록해야 합니까?",
        "options": [
            "A. Amazon S3",
            "B. Amazon ECR",
            "C. AWS CodeCommit",
            "D. SageMaker Feature Store"
        ],
        "answer": "B",
        "explanation": "SageMaker Studio에서 사용할 커스텀 Docker 이미지는 Amazon ECR(Elastic Container Registry)에 푸시되어야 하며, 이후 SageMaker 도메인 설정에서 연결해줘야 합니다."
    },
    {
        "question": "한 전자상거래 기업이 추천 시스템 모델을 배포한 후, 특정 연령대 그룹에 대해 추천 정확도가 눈에 띄게 낮다는 것을 발견했습니다. 모델이 특정 그룹에 대해 편향되어 있는지 확인하기 위해 사용해야 하는 가장 적합한 도구는 무엇입니까?",
        "options": [
            "A. SageMaker Debugger",
            "B. SageMaker Clarify",
            "C. SageMaker Model Monitor",
            "D. SageMaker Canvas"
        ],
        "answer": "B",
        "explanation": "SageMaker Clarify는 데이터 세트 및 학습된 모델의 편향(Bias)을 감지하는 기능을 제공합니다. 연령, 성별 등 특정 속성에 따른 모델의 성능 차이를 지표로 산출해 줍니다."
    },
    {
        "question": "SageMaker 엔드포인트의 가용성을 극대화하기 위해 다중 가용 영역(Multi-AZ)에 배포하려고 합니다. 다음 중 고가용성 보장을 위해 엔지니어가 취해야 할 행동으로 옳은 것은?",
        "options": [
            "A. 두 개의 다른 리전에 수동으로 엔드포인트를 생성한다.",
            "B. Endpoint Config에서 'InstanceCount'를 2 이상으로 설정한다.",
            "C. 엔드포인트 앞에 Network Load Balancer를 수동으로 구성한다.",
            "D. 모든 인스턴스를 하나의 프라이빗 서브넷에 몰아넣는다."
        ],
        "answer": "B",
        "explanation": "SageMaker는 관리형 서비스로서, InstanceCount를 2개 이상으로 설정하면 자동으로 가용 영역(AZ) 간에 인스턴스를 분산 배치하여 장애 대비를 수행합니다."
    },
    {
        "question": "모델 학습 작업 중 학습 손실(Training Loss)이 줄어들지 않고 정체되는 현상을 발견했습니다. 이 현상을 실시간으로 감지하여 엔지니어에게 알림을 보내고 학습을 중단시키려면 어떤 기능을 사용해야 합니까?",
        "options": [
            "A. SageMaker Model Monitor",
            "B. SageMaker Debugger Rules",
            "C. AWS CloudTrail",
            "D. SageMaker Neo"
        ],
        "answer": "B",
        "explanation": "SageMaker Debugger는 'stalled_training_rule'이나 'loss_not_decreasing' 같은 내장 규칙을 사용하여 학습 중 이상 징후를 감지하고 작업을 자동 중단할 수 있습니다."
    },
    {
        "question": "SageMaker Pipelines를 사용하여 모델을 학습시킨 후, 모델의 정확도가 특정 임계값(예: 0.85) 이상일 경우에만 모델을 등록(Register)하도록 구성하고 싶습니다. 어떤 단계(Step)를 파이프라인에 추가해야 합니까?",
        "options": [
            "A. TrainingStep",
            "B. ConditionStep",
            "C. RegisterModelStep",
            "D. ProcessingStep"
        ],
        "answer": "B",
        "explanation": "ConditionStep을 사용하면 파이프라인 실행 중 조건(IF-THEN) 로직을 구현할 수 있습니다. 성능 지표를 평가한 결과에 따라 다음 단계 진행 여부를 결정합니다."
    },
    {
        "question": "사용자가 커스텀 Docker 이미지를 사용하여 SageMaker에서 추론을 수행하려고 합니다. SageMaker가 컨테이너에 전달하는 추론 요청을 받기 위해 컨테이너가 반드시 수신 대기(Listen)해야 하는 포트 번호는 무엇입니까?",
        "options": [
            "A. 22",
            "B. 443",
            "C. 8080",
            "D. 80"
        ],
        "answer": "C",
        "explanation": "SageMaker의 추론용 사용자 지정 컨테이너는 반드시 8080 포트에서 HTTP 요청을 수신 대기하도록 설계되어야 합니다."
    },
    {
        "question": "SageMaker Studio 노트북에서 대규모 데이터 전처리를 위해 PySpark 스크립트를 작성했습니다. 이 스크립트를 별도의 관리형 Spark 클러스터에서 분산 실행하기 위해 가장 적합한 방법은?",
        "options": [
            "A. 노트북에서 로컬로 실행한다.",
            "B. SageMaker Processing Job을 사용하고 PySpark 프로세서를 지정한다.",
            "C. 스크립트를 AWS Lambda 함수로 변환한다.",
            "D. Amazon EC2 인스턴스를 수동으로 띄워 Spark를 설치한다."
        ],
        "answer": "B",
        "explanation": "SageMaker Processing은 PySpark 전용 컨테이너를 지원하며, 이를 통해 여러 인스턴스에 걸쳐 분산된 대규모 데이터 처리 작업을 서버리스 방식으로 실행할 수 있습니다."
    },
    {
        "question": "모델의 예측 결과가 실제 정답과 얼마나 일치하는지 모니터링하기 위해 '모델 품질(Model Quality)' 모니터링을 설정하려고 합니다. 이를 위해 필요한 데이터는 예측 데이터와 무엇입니까?",
        "options": [
            "A. 훈련 데이터 세트",
            "B. Ground Truth 데이터 (실제 정답 라벨)",
            "C. 하이퍼파라미터 로그",
            "D. CloudWatch 지표"
        ],
        "answer": "B",
        "explanation": "모델 품질 모니터링은 실제 환경에서의 예측 결과와 나중에 수집된 실제 정답(Ground Truth) 데이터를 비교하여 성능 지표(Accuracy 등)를 계산합니다."
    },
    {
        "question": "학습 데이터 세트가 너무 커서 단일 인스턴스에 다운로드하는 데 시간이 매우 오래 걸립니다. 데이터를 다운로드하지 않고 S3에서 직접 읽어오면서 동시에 데이터 가공을 병렬로 수행하기 위해 가장 적합한 것은?",
        "options": [
            "A. S3 복제 기능",
            "B. Amazon SageMaker Fast File Mode",
            "C. Amazon S3 Select",
            "D. Amazon EBS 프로비저닝"
        ],
        "answer": "B",
        "explanation": "Fast File Mode는 S3 데이터를 가상 파일 시스템으로 마운트하여 데이터를 다운로드하지 않고 스트리밍 방식으로 즉시 접근하게 해 줍니다."
    },
    {
        "question": "SageMaker에서 대규모 언어 모델(LLM)을 미세 조정(Fine-tuning)하려고 합니다. 모델 파라미터가 너무 많아 단일 GPU 메모리에 들어가지 않을 때 사용하는 기법은?",
        "options": [
            "A. Data Parallelism",
            "B. Model Parallelism (Sharded Data Parallelism)",
            "C. Local Training",
            "D. Sequence Parallelism"
        ],
        "answer": "B",
        "explanation": "모델의 크기가 커서 단일 GPU 메모리에 담기지 않는 경우, 모델을 쪼개서 여러 GPU에 배치하는 Model Parallelism이 필요합니다."
    },
    {
        "question": "SageMaker Feature Store에 저장된 데이터의 스키마를 관리하고, 외부 서비스인 Amazon Athena를 통해 특성 데이터를 쿼리하기 위해 필수적으로 연동되는 서비스는?",
        "options": [
            "A. AWS CodeCommit",
            "B. AWS Glue Data Catalog",
            "C. Amazon Redshift",
            "D. Amazon Kinesis"
        ],
        "answer": "B",
        "explanation": "SageMaker Feature Store의 오프라인 저장소(Offline Store)는 S3에 데이터를 저장하며, 이 데이터의 구조는 AWS Glue Data Catalog에 자동으로 등록되어 Athena 등에서 쿼리가 가능해집니다."
    },
    {
        "question": "한 팀이 SageMaker Studio 노트북 인스턴스를 공유하여 사용하고 있습니다. 특정 프로젝트의 보안을 위해 특정 사용자 그룹만 특정 S3 버킷에 접근할 수 있도록 제한하려고 합니다. 이를 구현하는 가장 효과적인 방법은 무엇입니까?",
        "options": [
            "A. S3 버킷에 공개 읽기 권한을 부여한다.",
            "B. 각 사용자의 IAM Execution Role에 조건부 S3 접근 정책을 적용한다.",
            "C. 모든 사용자를 동일한 IAM 관리자 그룹에 추가한다.",
            "D. VPC 보안 그룹에서 모든 아웃바운드 트래픽을 차단한다."
        ],
        "answer": "B",
        "explanation": "SageMaker Studio의 각 사용자 프로필(User Profile)에 할당된 IAM 실행 역할(Execution Role)에 특정 S3 리소스에 대한 접근 권한만을 명시한 정책을 적용함으로써 최소 권한 원칙을 준수할 수 있습니다."
    },
    {
        "question": "모델 학습 작업이 성공적으로 완료되었으나, 생성된 모델 아티팩트(.tar.gz) 내부에 일부 필요한 추론 코드가 누락된 것을 발견했습니다. SageMaker Python SDK를 사용할 때, 사용자 지정 코드를 아티팩트에 포함시키기 위해 지정해야 하는 파라미터는?",
        "options": [
            "A. entry_point 및 source_dir",
            "B. instance_type",
            "C. output_path",
            "D. role"
        ],
        "answer": "A",
        "explanation": "SageMaker SDK의 Estimator 설정 시 entry_point(실행 스크립트)와 source_dir(종속성 코드 디렉토리)을 지정하면, SageMaker가 해당 코드들을 묶어서 학습 컨테이너로 전달하고 결과물에 포함시킵니다."
    },
    {
        "question": "운영 환경에 배포된 모델이 입력 데이터의 변화에 따라 성능이 저하되는 현상을 모니터링하고 싶습니다. SageMaker Model Monitor를 구성할 때, 데이터의 '기본 통계 값(Baseline)'을 생성하기 위해 사용해야 하는 데이터는?",
        "options": [
            "A. 실시간 추론 요청 데이터",
            "B. 모델 학습에 사용된 훈련 데이터 세트",
            "C. 모델 아티팩트 로그",
            "D. 공개 데이터 세트"
        ],
        "answer": "B",
        "explanation": "Model Monitor는 훈련 데이터 세트의 통계적 특성을 기준(Baseline)으로 삼아, 실제 운영 데이터가 이 기준에서 얼마나 벗어나는지(Drift)를 비교합니다."
    },
    {
        "question": "SageMaker 엔드포인트에 Blue/Green 배포 전략을 적용하려고 합니다. 새로운 모델 버전(Green)을 배포한 후, 문제가 발생할 경우 즉시 이전 버전(Blue)으로 트래픽을 되돌릴 수 있게 해주는 기능은?",
        "options": [
            "A. Auto Scaling 정책",
            "B. UpdateEndpoint API의 DeploymentConfig",
            "C. S3 버전 관리",
            "D. CloudWatch 메트릭 알람"
        ],
        "answer": "B",
        "explanation": "SageMaker의 DeploymentConfig(Blue/Green 업데이트)를 사용하면 트래픽 이동 방식을 제어할 수 있으며, CloudWatch 알람과 연동하여 문제 발생 시 자동 롤백(Rollback) 기능을 제공합니다."
    },
    {
        "question": "ML 엔지니어가 모델의 학습 이력과 데이터 소스를 추적하여 향후 규제 기관의 감사에 대비해야 합니다. 모델 생성에 사용된 정확한 데이터 세트 버전과 파라미터를 기록하는 기능은 무엇입니까?",
        "options": [
            "A. SageMaker Lineage Tracking",
            "B. SageMaker Debugger",
            "C. AWS CloudTrail",
            "D. Amazon Inspector"
        ],
        "answer": "A",
        "explanation": "SageMaker ML Lineage Tracking은 데이터 원본, 알고리즘, 학습 결과물(Model Artifact) 간의 관계를 그래프 형태로 기록하여 모델의 생성 과정을 완벽히 재현하고 추적할 수 있게 합니다."
    },
    {
        "question": "SageMaker Batch Transform을 사용하여 수백만 건의 요청을 처리할 때, 인스턴스 자원을 최대한 활용하기 위해 한 번에 컨테이너로 보내는 HTTP 요청의 최대 크기를 조정하는 파라미터는?",
        "options": [
            "A. MaxConcurrentTransforms",
            "B. MaxPayloadInMB",
            "C. BatchStrategy",
            "D. InstanceCount"
        ],
        "answer": "B",
        "explanation": "MaxPayloadInMB는 배치 변환 작업 시 단일 HTTP 요청에 포함될 수 있는 데이터의 최대 크기를 제어하여 메모리 활용률을 최적화합니다."
    },
    {
        "question": "기업 내 공통 ML 환경을 구축하기 위해 SageMaker Studio 도메인을 VPC 전용 모드(VPC-only mode)로 설정했습니다. 이 설정의 주요 이점은 무엇입니까?",
        "options": [
            "A. 인터넷 속도가 더 빨라진다.",
            "B. 모든 트래픽이 공용 인터넷을 거치지 않고 VPC 엔드포인트를 통해 AWS 서비스와 통신한다.",
            "C. 설정 과정이 훨씬 간단해진다.",
            "D. 더 저렴한 인스턴스를 사용할 수 있다."
        ],
        "answer": "B",
        "explanation": "VPC 전용 모드는 보안 강화를 위해 사용되며, 모든 데이터 트래픽을 프라이빗 네트워크 내에 가두어 인터넷을 통한 유출 위험을 원천 차단합니다."
    },
    {
        "question": "학습 작업 중에 손실 함수(Loss) 값이 갑자기 NaN(Not a Number)으로 변하는 수치적 불안정성 문제를 해결하려고 합니다. 이 문제를 실시간으로 포착하기 위해 가장 적합한 도구는?",
        "options": [
            "A. SageMaker Clarify",
            "B. SageMaker Debugger",
            "C. SageMaker Neo",
            "D. Amazon EventBridge"
        ],
        "answer": "B",
        "explanation": "SageMaker Debugger는 학습 중 텐서 값을 실시간으로 검사하며, NaN 값 발생과 같은 수치 오류를 즉시 감지하여 알림을 보낼 수 있습니다."
    },
    {
        "question": "서로 다른 두 개의 모델이 순차적으로 실행되어야 합니다(예: 언어 감지 모델 후 번역 모델). 이를 하나의 엔드포인트에서 관리하기 위해 구성해야 하는 것은?",
        "options": [
            "A. Multi-model Endpoint",
            "B. Inference Pipeline",
            "C. Batch Transform",
            "D. Serverless Inference"
        ],
        "answer": "B",
        "explanation": "Inference Pipeline을 사용하면 여러 컨테이너(최대 15개)를 체인처럼 연결하여 단일 엔드포인트 호출로 순차적인 추론 프로세스를 실행할 수 있습니다."
    },
    {
        "question": "S3에 저장된 데이터 세트가 너무 많아 어떤 데이터가 최신 버전인지 관리하기가 어렵습니다. AWS Glue와 연동하여 데이터의 메타데이터를 관리하는 SageMaker의 기능은 무엇입니까?",
        "options": [
            "A. SageMaker Feature Store",
            "B. SageMaker Data Catalog 연동",
            "C. SageMaker Ground Truth",
            "D. SageMaker Studio Lab"
        ],
        "answer": "B",
        "explanation": "SageMaker는 AWS Glue Data Catalog와 연동하여 S3에 흩어진 데이터의 스키마와 위치 정보를 중앙에서 관리하고 쿼리할 수 있게 해줍니다."
    },
    {
        "question": "한 기업이 규제 준수를 위해 모든 SageMaker 추론 엔드포인트의 입력 데이터와 예측 결과 데이터를 6개월 동안 보관해야 합니다. 성능에 영향을 주지 않으면서 이를 구현하는 가장 효율적인 방법은 무엇입니까?",
        "options": [
            "A. 추론 코드 내에서 직접 데이터를 S3에 쓰는 로직을 추가한다.",
            "B. SageMaker Data Capture 기능을 활성화하고 S3 수명 주기 정책을 설정한다.",
            "C. 모든 추론 요청을 CloudWatch Logs에 기록한다.",
            "D. API Gateway를 통해 데이터를 Kinesis Data Firehose로 보낸다."
        ],
        "answer": "B",
        "explanation": "SageMaker Data Capture는 엔드포인트의 성능 저하 없이 비동기적으로 데이터를 S3에 저장하며, S3의 수명 주기 정책(Lifecycle Policy)을 통해 6개월 후 자동 삭제나 아카이브가 가능합니다."
    },
    {
        "question": "SageMaker Pipelines에서 각 단계(Step) 간에 공유되는 파일이나 산출물의 데이터 계보(Lineage)를 시각적으로 확인하고 관리할 수 있는 도구는 무엇입니까?",
        "options": [
            "A. SageMaker Model Registry",
            "B. SageMaker Studio의 Lineage 탐색기",
            "C. AWS CloudTrail",
            "D. Amazon QuickSight"
        ],
        "answer": "B",
        "explanation": "SageMaker Studio의 Lineage 탐색기를 사용하면 데이터 세트부터 훈련 작업, 등록된 모델에 이르기까지의 연결 고리를 시각적으로 추적할 수 있습니다."
    },
    {
        "question": "대규모 딥러닝 모델을 학습시키기 위해 수십 개의 GPU 인스턴스를 사용하고 있습니다. 인스턴스 간 데이터 전송 병목을 줄이기 위해 권장되는 AWS 전용 네트워크 장치는?",
        "options": [
            "A. Elastic Load Balancer",
            "B. Elastic Fabric Adapter (EFA)",
            "C. AWS Global Accelerator",
            "D. Amazon VPC Peering"
        ],
        "answer": "B",
        "explanation": "EFA는 OS 우회(OS-bypass) 기능을 통해 노드 간 통신 지연 시간을 획기적으로 낮춰주어, 분산 학습 작업의 효율을 극대화합니다."
    },
    {
        "question": "SageMaker Feature Store를 사용할 때, 실시간 추론 시 10ms 이하의 매우 낮은 지연 시간으로 최신 특성값을 읽어와야 합니다. 이때 읽기 요청을 보내야 하는 대상은?",
        "options": [
            "A. Offline Store",
            "B. Online Store",
            "C. Amazon S3",
            "D. AWS Glue Data Catalog"
        ],
        "answer": "B",
        "explanation": "Online Store는 저지연 읽기에 최적화된 키-값 저장소(주로 DynamoDB 기반)로 구성되어 있어 실시간 추론에 적합합니다."
    },
    {
        "question": "SageMaker Studio에서 작업 중인 데이터 과학자가 본인의 노트북 환경을 동료에게 그대로 공유하여 협업하고 싶습니다. 가장 권장되는 방법은 무엇입니까?",
        "options": [
            "A. 노트북 파일을 다운로드하여 이메일로 보낸다.",
            "B. SageMaker Studio의 공유 가능 스냅샷(Shared Snapshot URL) 기능을 사용한다.",
            "C. S3 버킷의 권한을 모든 사용자에게 개방한다.",
            "D. IAM 비밀번호를 공유한다."
        ],
        "answer": "B",
        "explanation": "공유 가능 스냅샷 기능을 사용하면 현재 작업 중인 노트북의 상태와 환경을 그대로 복제한 URL을 생성하여 동료에게 전달할 수 있습니다."
    },
    {
        "question": "모델의 특정 특성(Feature)이 예측 결과에 지나치게 큰 영향을 주고 있어 편향이 의심됩니다. 훈련된 모델의 특성 중요도를 SHAP 값을 통해 분석해 주는 기능은?",
        "options": [
            "A. SageMaker Debugger",
            "B. SageMaker Clarify",
            "C. SageMaker Model Monitor",
            "D. SageMaker Neo"
        ],
        "answer": "B",
        "explanation": "SageMaker Clarify는 모델의 투명성을 위해 특성 중요도를 분석하고 설명 가능성 리포트를 생성하는 표준 도구입니다."
    },
    {
        "question": "비용 절감을 위해 사용하지 않는 SageMaker 노트북 인스턴스를 자동으로 정지시키려고 합니다. 이를 구현하기 위해 가장 적합한 아키텍처는?",
        "options": [
            "A. 인스턴스를 매일 수동으로 확인한다.",
            "B. CloudWatch 지표(Idle 시간)와 Lambda 함수를 연동하여 정지 스크립트를 실행한다.",
            "C. 인스턴스 유형을 가장 낮은 사양으로 고정한다.",
            "D. 모든 사용자의 노트북 사용을 금지한다."
        ],
        "answer": "B",
        "explanation": "CloudWatch 지표를 모니터링하여 유휴 상태(Idle)가 일정 시간 지속될 경우 Lambda를 통해 StopNotebookInstance API를 호출하는 방식이 자동화 측면에서 가장 효율적입니다."
    },
    {
        "question": "SageMaker에서 모델을 학습시킬 때, 데이터 소스로 Amazon Redshift의 데이터를 직접 쿼리하여 사용하고 싶습니다. 어떤 기능을 활용해야 합니까?",
        "options": [
            "A. Amazon Redshift ML",
            "B. SageMaker Data Wrangler의 Redshift 커넥터",
            "C. S3에 데이터를 수동으로 Export한 후 학습",
            "D. AWS Glue를 통한 복잡한 ETL 작업"
        ],
        "answer": "B",
        "explanation": "SageMaker Data Wrangler는 Redshift, Athena 등 다양한 데이터 소스에 대한 기본 커넥터를 제공하여 데이터 이동 없이 시각적으로 쿼리하고 가공할 수 있게 해줍니다."
    },
    {
        "question": "새로운 모델의 추론 정확도가 90% 미만으로 떨어질 경우, 운영 중인 엔드포인트의 트래픽을 즉시 이전 버전으로 롤백하도록 설정하고 싶습니다. 어떤 서비스와 연동해야 합니까?",
        "options": [
            "A. AWS Config",
            "B. CloudWatch Alarms",
            "C. Amazon GuardDuty",
            "D. AWS Shield"
        ],
        "answer": "B",
        "explanation": "SageMaker의 배포 가드레일(Deployment Guardrails) 설정 시 CloudWatch Alarms를 지정하면, 지표가 임계값을 벗어날 때 자동으로 롤백이 수행됩니다."
    },
    {
        "question": "여러 팀이 하나의 AWS 계정에서 SageMaker를 사용 중이며, 팀별로 발생한 비용을 분리하여 정산(Chargeback)하고 싶습니다. 가장 적합한 관리 방법은?",
        "options": [
            "A. 팀별로 별도의 리전을 사용한다.",
            "B. 리소스에 태그(Tags)를 지정하고 AWS Cost Explorer에서 분석한다.",
            "C. 각 팀마다 별도의 AWS 계정을 생성한다.",
            "D. 매일 비용 보고서를 수동으로 작성한다."
        ],
        "answer": "B",
        "explanation": "AWS 리소스에 팀 이름 등의 태그를 부여하면, 비용 분석 도구에서 태그별로 필터링하여 정확한 팀별 사용 비용을 산출할 수 있습니다."
    }
]